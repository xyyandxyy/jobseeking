# 基础知识

## ViT处理流程:

在Vision Transformer (ViT) 中，图像的预处理过程主要包括将图像转换为适合Transformer模型输入的格式。以下是从原始图像到模型输入所进行的主要操作步骤：

1. 图像尺寸调整 (Resize)
   将输入图像调整为固定大小，通常是正方形（例如，224x224像素）。这是为了统一所有输入图像的尺寸，使得后续的处理更加简单。
   尺寸调整通常通过插值方法（如双线性插值）进行，保持图像的宽高比不变。
2. 划分图像块 (Patch Partitioning)
   将调整后的图像划分为固定大小的非重叠块（Patches），例如16x16像素或32x32像素。
   每个图像块可以被视为一个小的局部图像区域，这些块将作为ViT的输入。
3. 展平图像块 (Flattening Patches)
   将每个图像块展平成一维向量。如果图像块的大小是16x16像素，并且输入图像是RGB图像（即每个像素有3个通道），则每个块会被展平为一个长度为16x16x3=768的向量。
4. 线性映射 (Linear Projection)
   对每个展平后的图像块进行线性映射，将其投影到更高维度的空间中。这个步骤通常通过一个线性层实现，输出的维度与Transformer的隐藏层维度相匹配（如768或1024）。
   线性映射后，每个图像块被转换为具有固定长度的嵌入向量（Patch Embedding）。
5. 添加位置编码 (Add Positional Encoding)
   因为Transformer模型不具备CNN那样的空间信息感知能力，需要加入位置编码（Positional Encoding）来帮助模型理解图像块在原始图像中的位置。
   位置编码可以是固定的或可训练的，通常是与图像块的嵌入向量相加。
6. 生成分类标识符 (CLS Token)
   在输入序列的最前面添加一个特殊的分类标识符（CLS Token）。这个Token在Transformer处理完所有图像块后，将用于图像分类任务的最终输出。
   CLS Token也是一个向量，与图像块的嵌入向量具有相同的维度。
7. 构建输入序列 (Input Sequence)
   最终的输入序列包括CLS Token和所有图像块的嵌入向量，以及对应的位置信息。整个序列将作为ViT的输入，进入Transformer层进行进一步处理。
8. 标准化 (Normalization)
   在一些实现中，图像在被划分为图像块之前，会进行标准化处理，例如将像素值归一化到[0, 1]或[-1, 1]范围，或者减去均值再除以标准差。
9. 批量处理 (Batching)
   在实际应用中，通常会将多个图像组成一个批次（Batch）进行处理，以便于并行计算。批处理有助于加速训练过程。
10. 模型输入
    经过上述处理后，图像被转换为适合Transformer模型输入的格式，模型开始处理这些输入以进行图像分类或其他任务。
    简化流程图：
    原始图像 → 尺寸调整 → 划分图像块 → 展平成向量 → 线性映射 → 添加位置编码 → 添加CLS Token → 构建输入序列 → 标准化 → 批量处理 → 模型输入

## 如何计算显存占用 (WXG)

模型训练时，显存占用主要分为以下几个部分：

1. 模型参数

   就是模型的参数量乘以每一个数的字节数即可，比如float32就是4B，7B即70亿参数量，空间大小就是7x$10^9$x4B = 28GB。

   > 1GB = $10^9$ B

2. 梯度

   模型每个参数对应一个梯度，显存占用和权重占用是一样的。以上面为例，梯度占用空间就是28GB。

3. 优化器状态参数

   需要根据优化器的状态参数来计算。

   1. 如果是Adam/AdamW，每个权重参数都需要保存**动量**(一阶矩)和**方差****(二阶矩)，那么就是权重占用的两倍。
   2. 如果是带动量的SGD，那就需要**动量**，占用就是和权重一样。
   3. 如果是无动量的SGD，那就不需要额外的参数，因为SGD只需要梯度就可以了。

4. 激活值

   激活值大小主要取决于**batch size**和**层数**，具体可以表达为：
   $$
    B \times L \times Length \times S \times d 
   $$


   其中B是批大小，L是层数，Length是序列长度，S是精度单位，d是特征维度。

5. 缓存

   一般程序会保留一部分额外显存作为缓存，来协助CUDA的使用，一般需要1GB左右。

## Deepspeed 几个阶段介绍 (WXG)

## DP和DDP的区别

1. 使用场景不同

   - DP支持**单机多卡**和**多线程**，是一个**单进程**的框架。
   - DDP则支持**多机多卡**，同时也是**多进程**的。

2. 模型复制策略不同

   - 对于DP，处理每一个batch的时候，0号卡都需要把当前最新的模型复制给各个GPU。

     DP在主节点做reduce梯度求平均后，用这个梯度更新主节点的模型参数，然后在下一轮batch的时候，把主节点更新好的模型broadcast到每一个节点（模型复制）

   - 对于DDP，则是在开始的时候，0号卡将模型复制给各个GPU，这个复制只会发生一次。

     因为DDP在对local梯度做all reduce后(相当于单节点reduce+brodcast），每个节点用当前的全局平均梯度更新模型参数，所以在下一个batch时，所有节点都是更新好的模型。

3. 数据加载方式不同

   - 对于DP，0号卡读取**batch数据**, 然后再切分成小的batch传给各个GPU。
   - 对于DDP，会使用**DistributedSampler**, 将数据集划分成多个子集, 然后将**数据子集**传给各个GPU。

4. 通信次数不同

   - 对于DP，处理每个batch时需要多次通信，包括传输数据、模型复制、传送各个卡的模型输出、传送loss和梯度，几乎每一步都需要0号卡和其他卡之间的通信。
   - 对于DDP，处理每个batch时只需要0号卡和其他卡通信一次，也就是最后一步**给各个卡上的local梯度求平均**。

## 如何缓解过拟合, 有什么办法 (WXG)

1. **增加训练数据量**：更多的训练样本有助于模型学习真实的数据分布

2. **数据增强**：通过旋转、缩放、裁剪、噪声添加等方式人工扩充训练集

3. **正则化技术**：

   - L1正则化（Lasso）：促使部分权重变为零，实现特征选择

   - L2正则化（Ridge）：限制权重大小，防止单个特征影响过大

   - 弹性网络（Elastic Net）：结合L1和L2正则化的优点

4. **早停（Early Stopping）**：监控验证集性能，在性能开始下降时停止训练

5. **Dropout**：训练过程中随机丢弃一部分神经元
6. **批量归一化（Batch Normalization）**：稳定深层网络训练，具有轻微正则化效果
7. **学习率衰减**：逐渐减小学习率，避免在最优解附近震荡

8. **模型集成**：
   - Bagging（如随机森林）：训练多个模型并平均预测结果
   - Boosting（如XGBoost, AdaBoost）：顺序训练模型，每个模型关注前一个模型的错误
   - Stacking：组合多个基础模型的预测

9. **噪声注入**：向输入或权重添加随机噪声，增强鲁棒性
10. **权重约束**：限制神经网络权重的最大范数
11. **层归一化/实例归一化**：特别适用于RNN和风格迁移等任务
12. **Label Smoothing**：软化标签，在正确类别上分配一个略小于 1 的概率，而在其他类别上分配一个非零的小概率。
13. **混合训练（Mixup）**：创建样本和标签的凸组合用于训练: $ c=\lambda a+(1-\lambda) b$
14. **对抗训练**：使用对抗样本增强模型鲁棒性
15. **知识蒸馏**：用简单模型学习复杂模型的输出层logit, 或中间层logit. 当学生模型在学习教师模型的输出时，其本质上是在捕捉数据的全局信息，而不是简单地记住训练集中的每个样本细节。

## weight decay (WXG)

**weight decay** 通过调节模型复杂度对损失函数的影响, 防止模型过拟合。

其基本思想是: 就是给损失函数增加一个L2正则项
$$
L_{\text{total}}(\theta) = L(\theta) + \frac{\lambda}{2} \|\theta\|_2^2
$$
其中，$\|\theta\|_2^2$表示所有模型权重的L2范数的平方，λ控制正则化的力度。

***

在实际训练中，并不一定需要对模型中所有参数都施加 weight decay, 因为加 weight decay 会迫使这些参数向 0 靠拢

不需要进行weight decay的:

* **偏置项**. 没有必要.
* **Normalization**中的缩放与位移参数. 可能破坏归一化层恢复数据分布的能力.
* **嵌入层参数(**负责将词mapping到连续向量空间). 这通常会掩盖或削弱词语之间原有的语义关系

## 如何缓解样本不均衡的情况 (WXG)

1. **重采样技术**

   - **上采样**：增加少数类样本，如随机复制少数类样本
   - **下采样**：减少多数类样本，如随机移除部分多数类样本
   - **SMOTE**：合成少数类样本技术，通过在少数类样本之间插值生成新样本

2. **数据增强**

3. **加权损失函数**

   - 为不同类别样本分配不同权重，如根据样本数量的反比设置权重. 例如：加权交叉熵损失（Weighted Cross-Entropy）
     $$
     L_{\text{Weighted CE}} = -\sum_{c=1}^{C} w_c \, y_c \log (p_c)
     $$

4. **特殊损失函数**

   - **Focal Loss**：自动降低易分类样本的权重，关注难分类样本
     $$
     L_{FL} = -\sum_{c=1}^{C} \alpha_c\,(1-p_c)^{\gamma}\, y_c\, \log(p_c),
     $$
     Focal loss 是在标准交叉熵损失的基础上引入一个调制因子, 该调制因子在正确预测概率较高时会降低损失，让难分类的样本来主导Loss优化方向。

     

## 各种激活函数

- **Sigmoid**

  最基础的激活函数，函数值范围(0, 1)，公式如下：
  $$
   \sigma(x) = \frac{1}{1 + e^{-x}} \\ \sigma{\prime}(x) = \sigma(x) (1 - \sigma(x))
  $$


  缺点很简单，如果进入饱和区，那么梯度将会变小（梯度消失问题），其次是输出不对称。

  <img src="pic/image-20250311172258524.png" alt="image-20250311172258524" style="zoom:50%;" />

- **Tanh**

  Sigmoid改良，范围(-1, 1)：
  $$
   \text{Tanh}(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \\ \frac{d}{dx}\text{Tanh}(x) = 1 - \text{Tanh}^2(x)
  $$


  优点是输出是对称的，缺点是还是可能饱和。

  > **非对称激活函数（如 Sigmoid 函数，输出范围为 0 到 1）：**由于输出的非对称性，激活函数的平均值偏向于正值，导致梯度更新也有可能偏向某一特定方向。换句话说，如果输出范围总是正值，反向传播过程中会产生偏差，进而影响参数的更新，使得网络的学习效率下降。 **对称激活函数（如 Tanh 函数，输出范围为 -1 到 1）：**输出的对称性意味着激活函数的输出值可以同时分布在正负两侧，梯度更新也会更加平衡。由于输出的均值更接近 0，梯度更新的正负方向均能被有效考虑，这有助于加速收敛并提升训练效果。

  <img src="pic/image-20250311172326790.png" alt="image-20250311172326790" style="zoom:50%;" />

- **ReLU**

  $$ ReLU(x) = \max(0, x) $$

  导数很简单就不说了，主要的优点有四点：单侧抑制、相对宽阔的兴奋边界、及其容易计算的导数和稀疏激活性。缺点主要是0点的导数不可导以及“Dying ReLU”问题。

  <img src="pic/image-20250311172349886.png" alt="image-20250311172349886" style="zoom:50%;" />

## 几个优化器的异同

**SGD（随机梯度下降）**

- **基本思想**：在每一次参数更新时，仅利用当前批次 (mini-batch) 的梯度进行更新。

- **更新公式**：

  ```math
  \theta_{t+1} = \theta_t - \eta \nabla_{\theta} L(\theta_t)
  ```

  其中：  

  - \(\theta_t\) 表示第 \(t\) 次的参数  
  - \(\eta\) 为学习率  
  - \(\nabla_{\theta} L(\theta_t)\) 为当前梯度

- **特点**：简单直接，但容易陷入局部最优，并且在鞍点或陡峭/平缓区域表现不够稳定。

***

**SGD with Momentum （带动量的SGD）**

- **基本思想**：引入“动量”项，累计之前梯度的指数加权平均，从而在梯度下降的路上更平滑，有助于克服局部最小值和振荡问题。

- **更新公式**：

  ```math
  v_{t} = \gamma v_{t-1} + \eta \nabla_{\theta} L(\theta_t)
  ```

  ```math
  \theta_{t+1} = \theta_t - v_{t}
  ```

  其中：  

  - \(v_t\) 为当前动量，即梯度的累计  
  - \(\gamma\) 是动量因子（通常取值在0.9左右）

- **特点**：能在陡峭方向上加速收敛，同时在震荡区域可提供缓冲，克服SGD单纯使用梯度方向带来的问题。

***

**AdaGrad**

- **基本思想**：为每个参数自适应地调整学习率，依据历史梯度的累计平方调整，使得更新步长与该参数的历史梯度大小成反比。对稀疏数据非常友好。

- **更新公式**：

  ```math
  G_{t,i} = \sum_{\tau=1}^{t} g_{\tau,i}^2
  ```

  ```math
  \theta_{t+1,i} = \theta_{t,i} - \frac{\eta}{\sqrt{G_{t,i} + \epsilon}} g_{t,i}
  ```

  其中：  

  - \(g_{t,i}\) 为第 \(t\) 次迭代时第\(i\)个参数的梯度  
  - \(G_{t,i}\) 为历史梯度平方和  
  - \(\epsilon\) 为防止除零的小常数

- **特点**：对每个参数单独调节学习率，但累积的梯度平方容易逐步增大，导致后期学习率过小，更新过早停滞。

***

**RMSProp**

- **基本思想**：对AdaGrad进行改进，不直接累加所有历史梯度的平方，而是使用指数衰减的累积，这样可以在训练后期保持较合理的学习率。

- **更新公式**：

  ```math
  E[g^2]_t = \beta E[g^2]_{t-1} + (1-\beta) g_t^2
  ```

  ```math
  \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t
  ```

  其中：  

  - \(E[g^2]_t\) 为梯度平方的指数加权平均  
  - \(\beta\) 通常设置为0.9

- **特点**：能在学习过程中保持动态调整的学习率，不会像AdaGrad那样单调递减，适合大部分非凸问题。

***

**Adam**

- **基本思想**：结合了Momentum和RMSProp的思想，即同时维护梯度的一阶矩（均值）和二阶矩（未中心化的方差）的估计，从而实现对学习率的自适应调整。

  > * “一阶矩”在统计学中通常指均值（期望值）。在这里，它就是梯度的平均值，表示梯度的主要方向或趋势。
  > * “二阶矩”通常指的是随机变量平方的期望，未做中心化（即没有减去均值后再平方），因此它衡量的是梯度的幅度或能量，也可以看作是梯度“方差”（但注意这里是未中心化的方差）。

- **更新公式**：

  首先计算一阶和二阶矩的指数加权平均：

  ```math
  m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t
  ```

  ```math
  v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2
  ```

  然后进行偏差校正：

  > 在 Adam 算法中，我们会对过去的梯度进行一种“加权平均”，也就是计较之前的梯度对当前更新的贡献。因为一开始我们把这些历史梯度的值都设成了 0，所以前几次“平均”的时候，值会被零稀释掉，导致结果比实际的梯度值小（也就是“偏低”）。
  >
  > 偏差校正就是为了“补偿”最初因为历史信息不足而导致的低估问题

  ```math
  \hat{m}_t = \frac{m_t}{1-\beta_1^t}
  ```

  ```math
  \hat{v}_t = \frac{v_t}{1-\beta_2^t}
  ```

  最后参数更新：

  ```math
  \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t
  ```

  其中：  

  - \(\beta_1\) 和 \(\beta_2\) 分别对应一阶矩和二阶矩的衰减因子（常取 \(\beta_1=0.9\), \(\beta_2=0.999\)）  
  - \(\epsilon\) 是防止除零的小常数

- **特点**：结合了Momentum平滑和RMSProp的自适应学习率调整，能在大部分任务中表现出色，被广泛使用；缺点是相对于简单SGD计算复杂度更高，对超参数（如\(\beta_1, \beta_2\)）较为敏感。

***

AdamW



L1 L2



***

**总结异同**

- **共同点**：
  - 都是基于梯度下降思想的优化方法，用于最小化目标函数（如损失函数）。
  - 其更新公式都涉及当前梯度信息和学习率的调整。

- **不同点**：
  - **SGD**：利用当前梯度进行更新，简单但可能震荡或收敛慢。
  - **Momentum**：加入了历史梯度信息，加速收敛并平滑更新轨迹。
  - **AdaGrad**：根据所有历史梯度来调整学习率，适合稀疏数据，但后期可能导致学习率过低。
  - **RMSProp**：采用指数加权平均累积梯度平方，改善了AdaGrad的下降过快问题，使学习率保持在合理水平。
  - **Adam**：综合了Momentum和RMSProp，通过一阶和二阶矩的偏差校正实现更稳定的更新，被广泛应用于各类深度学习任务。

每种优化器各有优缺点，选择时需要根据具体任务、数据集特征和网络结构来权衡使用。

